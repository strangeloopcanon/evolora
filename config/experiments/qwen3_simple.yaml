host:
  backbone_type: gemma
  backbone_model: Qwen/Qwen3-0.6B
  tokenizer: Qwen/Qwen3-0.6B
  device: mps
  max_lora_rank: 8
  max_sequence_length: 256
  gen_max_new_tokens: 32

grid:
  families: [word.count, logic.bool, math]
  depths: [short]

energy:
  Emax: 6.0
  m: 0.5
  alpha: 5.0e-15
  beta: 0.015
  gamma: 0.0005
  lambda_p: 6.0e-8
  bankruptcy_grace: 2
  cost_scale: 0.6

pricing:
  base: 1.0
  k: 1.2
  min: 0.3
  max: 2.0

assimilation_tuning:
  per_cell_interval: 2
  max_merges_per_cell: 3
  seed_scale: 0.8
  soup_size: 3
  probe_max_other_cells: 1
  probe_required_passes: 1
  energy_floor: 0.0
  energy_floor_roi: 0.0
  energy_floor_base: 0.6
  energy_floor_roi_base: 0.9
  energy_topup_roi_bonus: 1.2
  gating_snapshot_limit: 64
  holdout_tasks_path: config/evaluation/holdout_simple.jsonl
  holdout_sample_size: 10
  holdout_margin: 0.02
  min_window: 8
  window_step: 2
  adaptive_decay: 0.82
  adaptive_floor: 0.0003
  holdout_max_retries: 3
  holdout_margin_step: 0.02
  bootstrap_uplift_enabled: true
  bootstrap_samples: 200
  permutation_samples: 200
  min_uplift_samples: 4
  dr_enabled: true
  dr_strata: [family, depth]
  dr_min_stratum_size: 3
  dr_min_power: 0.25
  merge_audit_enabled: true
  merge_method: fisher_svd
  merge_mode: hybrid
  trial_offspring_enabled: true
  trial_per_gen_cap: 5
  trial_stipend: 1.0
  trial_probation_gens: 8
  trial_promote_margin: 0.02
  trial_min_power: 0.2
  # Make evidence sizing adaptive on the ladder
  window_autotune: true
  min_window_min: 6

evolution:
  mutation_rate: 0.30
  assimilation_threshold: 0.0
  assimilation_p_value: 0.45
  max_merges_per_gen: 4
  min_population: 4
  max_population: 12

limits:
  lora_budget_frac: 0.04
  max_active_adapters_per_layer: 2

curriculum:
  lp_mix: 0.2
  lp_alpha: 0.5
  alp_auto_mix: true
  lp_mix_min: 0.1
  lp_mix_max: 0.6
  lp_window: 6

controller:
  tau: 0.40

qd:
  enabled: false

policy:
  enabled: true
  bias_strength: 0.5
  energy_cost: 0.05
  charge_tokens: false
  allowed_fields: [cell_pref, budget_frac, reserve_ratio, read, post, gate_bias_delta]

environment:
  synthetic_batch_size: 2
  auto_batch: true
  batch_min: 1
  batch_max: 3
  human_bandit_batch_size: 4
  max_episode_steps: 128
  energy_budget: 50.0
  success_reward_bonus: 1.0
  failure_cost_multiplier: 0.5

human_bandit:
  enabled: true
  preference_weight: 0.1
  helper_weight: 0.05
  frequency: 0.4

evaluation:
  enabled: true
  cadence: 10
  tasks_path: config/evaluation/holdout_simple.jsonl
  sample_size: 12
  reward_weight: 0.75

diversity:
  enabled: true
  energy_gini_cap: 0.85
  max_species_energy_share: 0.55

comms:
  enabled: true
  post_cost: 0.2
  read_cost: 0.1
  credit_frac: 0.2
  ttl: 10
